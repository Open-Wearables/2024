# ðŸ“„ Paper: M-MOVE-IT: Multimodal Machine Observation and Video-Enhanced Integration Tool for Data Annotation

**ðŸ‘¥ Authors:** Jacob Kamminga, Rob van der Duim, Erik ten Hove  
**ðŸ”— DOI:** [https://doi.org/10.1145/3675094.3678479](https://doi.org/10.1145/3675094.3678479)  
**ðŸ“š ACM DL:** [https://dl.acm.org/doi/abs/10.1145/3675094.3678479](hhttps://dl.acm.org/doi/abs/10.1145/3675094.3678479)

---

## ðŸ“„ Abstract

M-MOVE-IT is an open-source framework that simplifies data acquisition, annotation, and AI training for wearable technology. It addresses the challenges of synchronizing video and IMU data, making it easier to develop AI models for healthcare, sports, wildlife monitoring, anti-poaching, and livestock management applications. The framework automates and streamlines managing sensors, subjects, and deployments, synchronizing data, and annotating activities. M-MOVE-IT uses the real-time clocks of sensors and an offset annotation step to achieve precise synchronization, automatically parses sensor metadata, and generates annotation tasks. The export module provides data in JSON format for easy use in AI training. M-MOVE-IT's design supports active learning and human-in-the-loop development, enhancing the efficiency and scalability of wearable technology research.

---

## ðŸªª License

UNKNOWN
